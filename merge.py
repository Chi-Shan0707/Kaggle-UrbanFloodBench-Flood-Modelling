import csv
import os
import sys
from tqdm import tqdm  # æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œè®©ä½ çŸ¥é“æ²¡å¡æ­»

# ================= é…ç½®åŒºåŸŸ =================
# åœ¨è¿™é‡Œå¡«å…¥ä½ è¦åˆå¹¶çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒæ— é™å¤šä¸ªï¼‰
INPUT_FILES = [
    "submission.csv",  # ç¬¬ä¸€ä¸ªæ–‡ä»¶
    "submission_plus.csv"   # ç¬¬äºŒä¸ªæ–‡ä»¶
]

OUTPUT_FILE = "final_submission.csv"
# ===========================================

def merge_csv_stream(input_files, output_file):
    print(f"å‡†å¤‡åˆå¹¶ä»¥ä¸‹æ–‡ä»¶åˆ° {output_file}:")
    for f in input_files:
        print(f"  - {f}")
        if not os.path.exists(f):
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {f}")
            return

    # Kaggle æäº¤è¦æ±‚çš„åˆ—é¡ºåº
    # å¿…é¡»ç¡®ä¿è¿™ä¸€è¡Œæ˜¯ä½  csv é‡Œå®é™…çš„åˆ—åï¼ˆé™¤äº† row_id ä¼šè¢«é‡ç½®ï¼‰
    headers = ['row_id', 'model_id', 'event_id', 'node_type', 'node_id', 'water_level']
    
    current_row_id = 0
    
    # ä½¿ç”¨ buffer_size ä¼˜åŒ–å†™å…¥é€Ÿåº¦
    with open(output_file, 'w', newline='', encoding='utf-8') as f_out:
        writer = csv.writer(f_out)
        
        # 1. å†™å…¥è¡¨å¤´
        writer.writerow(headers)
        
        # 2. é€ä¸ªæ–‡ä»¶å¤„ç†
        for file_path in input_files:
            print(f"\næ­£åœ¨æµå¼å¤„ç†: {file_path} ...")
            
            # ä¼°ç®—è¡Œæ•°ç”¨äºè¿›åº¦æ¡ï¼ˆä¸åŠ è½½æ–‡ä»¶ï¼‰
            try:
                # è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿä¼°ç®—è¡Œæ•°çš„æ–¹æ³•ï¼Œå¦‚æœæ˜¯ Linux ç³»ç»Ÿ
                # å¦‚æœæŠ¥é”™æˆ–æ˜¯ Windowsï¼Œtqdm ä¼šè‡ªåŠ¨é™çº§ä¸ºä¸æ˜¾ç¤ºæ€»æ•°æ¨¡å¼
                total_lines = sum(1 for _ in open(file_path, 'rb')) - 1
            except:
                total_lines = None

            with open(file_path, 'r', encoding='utf-8') as f_in:
                # ä½¿ç”¨ DictReader è‡ªåŠ¨è¯†åˆ«åˆ—åï¼Œé˜²æ­¢åˆ—é¡ºåºä¸ä¸€è‡´
                reader = csv.DictReader(f_in)
                
                # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—ï¼ˆé™¤äº† row_idï¼‰
                # åªè¦æœ‰æ•°æ®åˆ—å³å¯ï¼Œrow_id æˆ‘ä»¬ä¼šè¦†ç›–
                required_cols = ['model_id', 'event_id', 'node_type', 'node_id', 'water_level']
                if not all(col in reader.fieldnames for col in required_cols):
                    print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ç¼ºå°‘å¿…è¦çš„åˆ—ï¼")
                    print(f"   ç°æœ‰åˆ—: {reader.fieldnames}")
                    return

                # é€è¡Œè¯»å–ï¼Œä¿®æ”¹ row_idï¼Œé€è¡Œå†™å…¥
                # å†…å­˜å ç”¨æä½ï¼Œåªå­˜å½“å‰è¿™ä¸€è¡Œ
                for row in tqdm(reader, total=total_lines, unit="row"):
                    writer.writerow([
                        current_row_id,
                        row['model_id'],
                        row['event_id'],
                        row['node_type'],
                        row['node_id'],
                        row['water_level']
                    ])
                    current_row_id += 1

    print("\n" + "="*40)
    print(f"âœ… åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ”¢ æ€»è¡Œæ•° (row_id): 0 åˆ° {current_row_id - 1}")
    print("="*40)

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å®‰è£… tqdm


    merge_csv_stream(INPUT_FILES, OUTPUT_FILE)