"""preprocess.py â€” å°†æ‰€æœ‰ CSV æ–‡ä»¶æ‰¹é‡è½¬æ¢ä¸º .pt æ ¼å¼ã€‚

è¾“å‡ºç‰©ï¼š
  1. Models/Model_{id}/{split}/static_graph.pt
       åŒ…å«å›¾çš„å®Œæ•´é™æ€ç»“æ„ï¼ˆèŠ‚ç‚¹ç‰¹å¾ã€è¾¹ç´¢å¼•ã€è¾¹é™æ€ç‰¹å¾ã€orig_idx æ˜ å°„ï¼‰

  2. Models/Model_{id}/{split}/event_{N}/event_data.pt
       åŒ…å«è¯¥äº‹ä»¶çš„åŠ¨æ€æ—¶åºå¼ é‡ï¼ˆèŠ‚ç‚¹ + è¾¹ï¼‰ï¼Œä»¥åŠ timesteps ç­‰å…ƒæ•°æ®

ä½¿ç”¨æ–¹æ³•ï¼š
  python preprocess.py                           # å¤„ç† Model 1/2 çš„ train/test
  python preprocess.py --model_id 2 --split train   # ä»…å¤„ç†æŒ‡å®šæ¨¡å‹/åˆ†ç‰‡
  python preprocess.py --overwrite               # å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„ .pt æ–‡ä»¶

è¯´æ˜ï¼š
  - ä¸ä¾èµ– torch_geometricï¼Œçº¯ pandas + numpy + torchã€‚
  - ä¸ dataset.py çš„ç´¢å¼•æ˜ å°„é€»è¾‘å®Œå…¨ä¸€è‡´ï¼ˆä»¥ node_idx åˆ—ä¸ºå‡†ï¼‰ã€‚
  - å·²å­˜åœ¨çš„ .pt æ–‡ä»¶é»˜è®¤è·³è¿‡ï¼›æ·»åŠ  --overwrite å¼ºåˆ¶è¦†ç›–ã€‚
"""

import os
import argparse
import numpy as np
import pandas as pd
import torch
from tqdm import tqdm


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é€šç”¨å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_map(df: pd.DataFrame, col: str = 'node_idx') -> dict:
    """å°† DataFrame col åˆ—çš„åŸå§‹ ID æ˜ å°„åˆ° 0-based è¿ç»­æ•´æ•°ç´¢å¼•ã€‚"""
    return {int(v): i for i, v in enumerate(df[col].values)}


def _build_edge_index(df: pd.DataFrame, src_map: dict, dst_map: dict) -> torch.Tensor:
    """ä» edge DataFrame æ„å»º [2, E] æ•´æ•° edge_indexï¼Œè‡ªåŠ¨è¿‡æ»¤æ— æ³•æ˜ å°„çš„è¡Œã€‚"""
    srcs = df['from_node'].astype(int).map(src_map).values
    dsts = df['to_node'].astype(int).map(dst_map).values
    valid = (~np.isnan(srcs.astype(float))) & (~np.isnan(dsts.astype(float)))
    return torch.from_numpy(
        np.vstack([srcs[valid], dsts[valid]]).astype(np.int64)
    )  # [2, E]


def _safe_float_tensor(df: pd.DataFrame, cols: list) -> torch.Tensor:
    """æå–æŒ‡å®šåˆ—ï¼ŒNaNâ†’0ï¼Œè¿”å› float32 Tensorã€‚"""
    return torch.from_numpy(df[cols].fillna(0).astype(np.float32).values)


def _load_edge_dyn(csv_path: str, T: int, E: int) -> torch.Tensor:
    """åŠ è½½è¾¹åŠ¨æ€ CSV â†’ Tensor [T, E, 2]ï¼ˆflow, velocityï¼‰ã€‚
    æ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›å…¨é›¶å¼ é‡ã€‚
    """
    arr = np.zeros((T, E, 2), dtype=np.float32)
    if not os.path.exists(csv_path):
        return torch.from_numpy(arr)
    df = pd.read_csv(csv_path)
    for t_idx, grp in df.groupby('timestep'):
        idxs = grp['edge_idx'].values.astype(int)
        valid = (idxs >= 0) & (idxs < E)
        arr[int(t_idx), idxs[valid], :] = \
            grp[['flow', 'velocity']].values[valid].astype(np.float32)
    return torch.from_numpy(arr)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é™æ€å›¾å¤„ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_static_graph(base_dir: str, overwrite: bool = False) -> dict:
    """ä» base_dir ä¸‹çš„ CSV æ„å»ºé™æ€å›¾å¹¶ä¿å­˜ä¸º static_graph.ptã€‚

    ä¿å­˜å­—å…¸ keyï¼š
      man_static     [N1, 4]   manhole èŠ‚ç‚¹é™æ€ç‰¹å¾
      man_orig_idx   [N1]      manhole åŸå§‹ node_idxï¼ˆæ¨ç†ç»“æœå¯¹é½ç”¨ï¼‰
      cell_static    [N2, 6]   cell èŠ‚ç‚¹é™æ€ç‰¹å¾
      cell_orig_idx  [N2]      cell åŸå§‹ node_idx
      man2man_ei     [2, E1]   1Dâ†’1D edge_index
      man2man_attr   [E1, 7]   1D edge é™æ€ç‰¹å¾
      cell2cell_ei   [2, E2]   2Dâ†’2D edge_index
      cell2cell_attr [E2, 5]   2D edge é™æ€ç‰¹å¾
      man2cell_ei    [2, C]    manholeâ†’cell è€¦åˆ edge_index
      cell2man_ei    [2, C]    cellâ†’manhole è€¦åˆ edge_index
      N1, N2, E1, E2           èŠ‚ç‚¹/è¾¹æ•°é‡ï¼ˆintï¼‰
    """
    output_path = os.path.join(base_dir, 'static_graph.pt')
    if os.path.exists(output_path) and not overwrite:
        print(f"  âœ… static_graph.pt å·²å­˜åœ¨ï¼Œè·³è¿‡æ„å»º")
        return torch.load(output_path, weights_only=False)

    # â”€â”€ èŠ‚ç‚¹é™æ€ç‰¹å¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    man_df  = pd.read_csv(os.path.join(base_dir, '1d_nodes_static.csv'))
    cell_df = pd.read_csv(os.path.join(base_dir, '2d_nodes_static.csv'))

    man_map  = _build_map(man_df)
    cell_map = _build_map(cell_df)
    N1, N2   = len(man_map), len(cell_map)

    man_static  = _safe_float_tensor(
        man_df, ['depth', 'invert_elevation', 'surface_elevation', 'base_area'])
    cell_static = _safe_float_tensor(
        cell_df, ['area', 'roughness', 'min_elevation', 'elevation', 'aspect', 'curvature'])

    # â”€â”€ è¾¹ç´¢å¼• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    e1_df  = pd.read_csv(os.path.join(base_dir, '1d_edge_index.csv'))
    e2_df  = pd.read_csv(os.path.join(base_dir, '2d_edge_index.csv'))
    cpl_df = pd.read_csv(os.path.join(base_dir, '1d2d_connections.csv'))

    man2man_ei   = _build_edge_index(e1_df, man_map, man_map)
    cell2cell_ei = _build_edge_index(e2_df, cell_map, cell_map)

    src_1d   = cpl_df['node_1d'].astype(int).map(man_map).values
    dst_2d   = cpl_df['node_2d'].astype(int).map(cell_map).values
    valid_c  = (~np.isnan(src_1d.astype(float))) & (~np.isnan(dst_2d.astype(float)))
    src_1d   = src_1d[valid_c].astype(np.int64)
    dst_2d   = dst_2d[valid_c].astype(np.int64)

    man2cell_ei = torch.from_numpy(np.vstack([src_1d, dst_2d]))
    cell2man_ei = torch.from_numpy(np.vstack([dst_2d, src_1d]))

    E1 = man2man_ei.shape[1]
    E2 = cell2cell_ei.shape[1]

    # â”€â”€ è¾¹é™æ€ç‰¹å¾ï¼ˆå¯é€‰ï¼Œæ–‡ä»¶ä¸å­˜åœ¨æ—¶å…¨é›¶ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _edge_static(fname, cols):
        p = os.path.join(base_dir, fname)
        if not os.path.exists(p):
            return torch.zeros(0, len(cols), dtype=torch.float32)
        df = pd.read_csv(p).sort_values('edge_idx').reset_index(drop=True)
        return _safe_float_tensor(df, cols)

    man2man_attr   = _edge_static('1d_edges_static.csv',
        ['relative_position_x', 'relative_position_y',
         'length', 'diameter', 'shape', 'roughness', 'slope'])
    cell2cell_attr = _edge_static('2d_edges_static.csv',
        ['relative_position_x', 'relative_position_y',
         'face_length', 'length', 'slope'])

    # â”€â”€ ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    graph = {
        'man_static'    : man_static,
        'man_orig_idx'  : torch.from_numpy(man_df['node_idx'].astype(np.int64).values),
        'cell_static'   : cell_static,
        'cell_orig_idx' : torch.from_numpy(cell_df['node_idx'].astype(np.int64).values),
        'man2man_ei'    : man2man_ei,
        'man2man_attr'  : man2man_attr,
        'cell2cell_ei'  : cell2cell_ei,
        'cell2cell_attr': cell2cell_attr,
        'man2cell_ei'   : man2cell_ei,
        'cell2man_ei'   : cell2man_ei,
        'N1': N1, 'N2': N2, 'E1': E1, 'E2': E2,
    }
    torch.save(graph, output_path)
    print(f"  ğŸ’¾ static_graph.pt å·²ä¿å­˜: N1={N1}, N2={N2}, E1={E1}, E2={E2}")
    return graph


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŠ¨æ€äº‹ä»¶å¤„ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_event(event_path: str, man_map: dict, cell_map: dict,
                  E1: int, E2: int, overwrite: bool = False) -> None:
    """å°†å•ä¸ª event ç›®å½•ä¸‹çš„ CSV è½¬æ¢ä¸º event_data.ptã€‚

    ä¿å­˜å­—å…¸ keyï¼š
      manhole    [T, N1, 2]   water_level, inlet_flow
      cell       [T, N2, 3]   rainfall, water_level, water_volume
      1d_edges   [T, E1, 2]   flow, velocity
      2d_edges   [T, E2, 2]   flow, velocity
      timesteps  int           æ—¶é—´æ­¥æ•° T
      tstamp_df  DataFrame     åŸå§‹ timesteps.csvï¼ˆå« timestamp åˆ—ï¼‰
    """
    output_path = os.path.join(event_path, 'event_data.pt')
    if os.path.exists(output_path) and not overwrite:
        return

    man_dyn_fp  = os.path.join(event_path, '1d_nodes_dynamic_all.csv')
    cell_dyn_fp = os.path.join(event_path, '2d_nodes_dynamic_all.csv')
    ts_fp       = os.path.join(event_path, 'timesteps.csv')

    if not (os.path.exists(man_dyn_fp) and os.path.exists(cell_dyn_fp)):
        print(f"  âŒ ç¼ºå°‘åŠ¨æ€æ–‡ä»¶ï¼Œè·³è¿‡: {os.path.basename(event_path)}")
        return

    ts_df = pd.read_csv(ts_fp)
    T     = len(ts_df)
    N1    = len(man_map)
    N2    = len(cell_map)

    # Manhole [T, N1, 2]
    man_arr = np.zeros((T, N1, 2), dtype=np.float32)
    for t_idx, grp in pd.read_csv(man_dyn_fp).groupby('timestep'):
        idxs  = grp['node_idx'].map(man_map).values
        valid = ~np.isnan(idxs.astype(float))
        man_arr[int(t_idx), idxs[valid].astype(int), :] = \
            grp[['water_level', 'inlet_flow']].values[valid].astype(np.float32)

    # Cell [T, N2, 3]
    cell_arr = np.zeros((T, N2, 3), dtype=np.float32)
    for t_idx, grp in pd.read_csv(cell_dyn_fp).groupby('timestep'):
        idxs  = grp['node_idx'].map(cell_map).values
        valid = ~np.isnan(idxs.astype(float))
        cell_arr[int(t_idx), idxs[valid].astype(int), :] = \
            grp[['rainfall', 'water_level', 'water_volume']].values[valid].astype(np.float32)

    torch.save({
        'manhole'   : torch.from_numpy(man_arr),
        'cell'      : torch.from_numpy(cell_arr),
        '1d_edges'  : _load_edge_dyn(
            os.path.join(event_path, '1d_edges_dynamic_all.csv'), T, E1),
        '2d_edges'  : _load_edge_dyn(
            os.path.join(event_path, '2d_edges_dynamic_all.csv'), T, E2),
        'timesteps' : T,
        'tstamp_df' : ts_df,
    }, output_path)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»å¤„ç†å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_split(root_dir: str, model_id: int, split: str,
                  overwrite: bool = False) -> None:
    """å¤„ç†å•ä¸ª (model_id, split) ç»„åˆçš„æ‰€æœ‰æ•°æ®ã€‚"""
    base_dir = os.path.join(root_dir, f'Models/Model_{model_id}/{split}')

    if not os.path.exists(base_dir):
        print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {base_dir}")
        return

    print(f"\nğŸš€ Model {model_id} - {split}  ({base_dir})")

    # 1. é™æ€å›¾ï¼ˆå«è¾¹ç´¢å¼• + è¾¹/èŠ‚ç‚¹é™æ€ç‰¹å¾ï¼‰
    graph = process_static_graph(base_dir, overwrite=overwrite)
    N1, N2, E1, E2 = graph['N1'], graph['N2'], graph['E1'], graph['E2']
    man_map  = {int(v): i for i, v in enumerate(graph['man_orig_idx'].tolist())}
    cell_map = {int(v): i for i, v in enumerate(graph['cell_orig_idx'].tolist())}

    # 2. æ‰€æœ‰ event åŠ¨æ€æ•°æ®
    event_dirs = sorted([
        d for d in os.listdir(base_dir)
        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith('event_')
    ])

    for ev in tqdm(event_dirs, desc=f'  M{model_id}-{split} CSVâ†’PT'):
        process_event(os.path.join(base_dir, ev),
                      man_map, cell_map, E1, E2, overwrite=overwrite)

    print(f"  âœ… {len(event_dirs)} ä¸ª event å¤„ç†å®Œæ¯•ã€‚")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='é¢„å¤„ç† CSV â†’ PT æ–‡ä»¶')
    parser.add_argument('--model_id', type=int, default=None,
                        help='æŒ‡å®šæ¨¡å‹ IDï¼ˆä¸æŒ‡å®šåˆ™å¤„ç† 1 å’Œ 2ï¼‰')
    parser.add_argument('--split', type=str, default=None,
                        choices=['train', 'test'],
                        help='æŒ‡å®š splitï¼ˆä¸æŒ‡å®šåˆ™å¤„ç† train å’Œ testï¼‰')
    parser.add_argument('--root', type=str, default='./',
                        help='é¡¹ç›®æ ¹ç›®å½•ï¼ˆå« Models/ å­ç›®å½•ï¼‰')
    parser.add_argument('--overwrite', action='store_true',
                        help='å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„ .pt æ–‡ä»¶')
    args = parser.parse_args()

    model_ids = [args.model_id] if args.model_id else [1, 2]
    splits    = [args.split]    if args.split    else ['train', 'test']

    for mid in model_ids:
        for sp in splits:
            process_split(root_dir=args.root, model_id=mid,
                          split=sp, overwrite=args.overwrite)

    print('\nâœ… å…¨éƒ¨é¢„å¤„ç†å®Œæˆï¼')
